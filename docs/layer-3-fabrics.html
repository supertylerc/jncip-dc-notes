
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Layer 3 Fabrics &#8212; jncip-dc-notes  documentation</title>
    <link rel="stylesheet" href="static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="static/documentation_options.js"></script>
    <script type="text/javascript" src="https://code.jquery.com/jquery-3.4.1.min.js"></script>
    <script type="text/javascript" src="static/underscore.js"></script>
    <script type="text/javascript" src="static/doctools.js"></script>
    <script type="text/javascript" src="static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="VXLAN" href="vxlan.html" />
    <link rel="prev" title="Layer 2 Fabrics" href="layer-2-fabrics.html" />
   
  <link rel="stylesheet" href="static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="layer-3-fabrics">
<span id="id1"></span><h1>Layer 3 Fabrics<a class="headerlink" href="#layer-3-fabrics" title="Permalink to this headline">¶</a></h1>
<p>This blueprint item primarily covers the following topics:</p>
<ul class="simple">
<li><a class="reference internal" href="#clos"><span class="std std-ref">3-Stage Clos Architecture</span></a></li>
<li><a class="reference internal" href="#ip-fabric-routing"><span class="std std-ref">IP Fabric Routing</span></a></li>
<li><a class="reference internal" href="#ip-fabric-scaling"><span class="std std-ref">IP Fabric Scaling</span></a></li>
<li><a class="reference internal" href="#best-practices"><span class="std std-ref">IP Fabric Best Practices</span></a></li>
</ul>
<div class="section" id="stage-clos-architecture">
<span id="clos"></span><h2>3-Stage Clos Architecture<a class="headerlink" href="#stage-clos-architecture" title="Permalink to this headline">¶</a></h2>
<p>A Clos network was originally a circuit switching architecture for the
PSTN.  It provided for connecting one input to one output with no
blocking.  In other words, connectivity was always possible.  This was
because of the intermediate switches that connected ingress and egress
switches.</p>
<p>In IP networking, this concept has been applied in the “spine-leaf”
architecture.  In this design, a number of interconnecting transport
switches (spines) connect to ingress and egress switches (leafs).  They
provide multiple paths for communications and can be designed in a way
that is “non-blocking” if zero oversubscription is desired.  These
fabrics make better use of their links.  They are classified as
<code class="docutils literal notranslate"><span class="pre">n-stage</span></code>, where <code class="docutils literal notranslate"><span class="pre">n</span></code> is (more or less) the number of network devices
a packet will traverse when ingressing and egressing from any point in
the fabric to any point in the fabric.  A 3-stage architecture consists
of three network devices from point A to point Z: the ingress leaf, a
spine, and an egress leaf.  This means that you can have predictable
network characteristics such as hop count and latency.  For example, for
intra-fabric communications, any destination is exactly two hops from
its source (excluding advanced services such as overlay networking,
firewalls, load balancers, etc.).</p>
</div>
<div class="section" id="ip-fabric-routing">
<span id="id2"></span><h2>IP Fabric Routing<a class="headerlink" href="#ip-fabric-routing" title="Permalink to this headline">¶</a></h2>
<p>When designing an IP fabric, there are two primary designs, though both
leverage BGP.</p>
<div class="section" id="ibgp">
<span id="id3"></span><h3>iBGP<a class="headerlink" href="#ibgp" title="Permalink to this headline">¶</a></h3>
<p>In an iBGP design, an IGP such as OSPF or IS-IS is used to provide
multipathing.  iBGP peerings are formed over loopback interfaces, and
route reflectors can be used to increase the scale of the solution.
Route reflection, however, introduces its own issues.</p>
<p>When the same prefix is received from multiple leafs by a route
reflector spine, it will (by default) only advertise the best path to
the non-route-reflector spines.  This results in suboptimal traffic
forwarding, and in congested scenarios may result in avoidable
congestion and degradation of service.  To resolve this issue, BGP
ADD-PATH can be used.  BGP ADD-PATH causes the router to prefix a unique
path identifier to a prefix advertisement; because of this, all routers
at the spine level must support and be configured for BGP ADD-PATH.</p>
</div>
<div class="section" id="ebgp">
<span id="id4"></span><h3>eBGP<a class="headerlink" href="#ebgp" title="Permalink to this headline">¶</a></h3>
<p>With eBGP, there is no IGP – BGP acts in a similar role as an IGP.  In
this design, each leaf node is given a unique ASN and all spines either
share the same ASN or have unique ASNs per node.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The QFX5100 Series book <a class="footnote-reference" href="#f1" id="id5">[1]</a>, particularly Chapter 7: IP Fabrics
(Clos), seems to suggest that the spine switches should each have a
unique ASN.  However, multiple other sources such as RFC7938 <a class="footnote-reference" href="#f2" id="id6">[2]</a>
and BGP in the Data Center <a class="footnote-reference" href="#f3" id="id7">[3]</a> suggest giving the spines the same
ASN while allowing the leafs to have unique ASNs.  This is likely to
avoid the nead for <code class="docutils literal notranslate"><span class="pre">multipath</span> <span class="pre">multiple-as</span></code> on every leaf and to
simplify spine configuration.  However, even following this numbering
scheme, the spines will ultimately require <code class="docutils literal notranslate"><span class="pre">multipath</span> <span class="pre">multiple-as</span></code>.</p>
</div>
<p>You might notice that because of this design, you will still need extra
configuration to handle the scenario where a prefix is received from
multiple switches.  To work around this, use the
<code class="docutils literal notranslate"><span class="pre">set</span> <span class="pre">protocols</span> <span class="pre">bgp</span> <span class="pre">group</span> <span class="pre">&lt;name&gt;</span> <span class="pre">multipath</span> <span class="pre">multiple-as</span></code> BGP
configuration.  The biggest difference between this an the requirement
for ADD-PATH in an <a class="reference internal" href="#ibgp"><span class="std std-ref">iBGP</span></a> is that ADD-PATH is a feature negotiated
between peers, whereas <code class="docutils literal notranslate"><span class="pre">multipath</span> <span class="pre">multiple-as</span></code> is not.  This results
in less complexity and fewer places for things to go wrong.  It also
increases vendor and platform interoperability since ADD-PATH is not
guaranteed to be supported on a given platform or vendor, but even
without <code class="docutils literal notranslate"><span class="pre">multipath</span> <span class="pre">multiple-as</span></code>, the fabric will still function
(suboptimally).  Additionally, if the spine switches are given the same
ASN instead of a unique ASN per spine switch, the number of places that
require <code class="docutils literal notranslate"><span class="pre">multipath</span> <span class="pre">multiple-as</span></code> might be reduced depending on your
design and requirements.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><code class="docutils literal notranslate"><span class="pre">multipath</span> <span class="pre">multiple-as</span></code> is recommended on all nodes.  You <em>can</em> get
away with only deploying it in certain places, but that doesn’t mean
you should.  One of the benefits of deploying an IP fabric is
reproducibility, and when you start tailoring to such a degree, it
increases the cognitive load on engineers supporting the fabric
because they can no longer assume similar behavior amongst nodes.</p>
</div>
</div>
</div>
<div class="section" id="ip-fabric-scaling">
<span id="id8"></span><h2>IP Fabric Scaling<a class="headerlink" href="#ip-fabric-scaling" title="Permalink to this headline">¶</a></h2>
<p>The scalability of an IP fabric is largely limited by three things:</p>
<ul class="simple">
<li>the acceptable oversubscription ratio</li>
<li>the number of uplinks available per leaf per pod</li>
<li>the number of ports per spine per pod</li>
</ul>
<p>The acceptable oversubscription ratio can determine both how many
servers you attach to a leaf and how many spines you need to have, both
of which influence and are influenced by your required speeds downstream
toward servers.  For example, assume you have a 48x10G switch with
6x40G uplinks.  This gives you an oversubscription ratio of 480G:240G,
or 2:1, if you have six spine switches.  However, perhaps it’s
unacceptable to have a 2:1 oversubscription ratio.  Maybe you require no
oversubscription.  In this case, you can either select a leaf switch
with more 40G uplinks (and add more spine swithces), or you can decide
that you will not attach any servers to half of the 10G ports.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You can get clever and, if your switch supports it, break out all of
the 40G ports to 10G ports.  Then use only 10G spines.  Split your
total 10G ports in half; this number is the number of spines you
need.  For example, given the same leaf port density above and
breaking out the 40G ports, you would have 72x10G interfaces.
Dividing this by two, there are 36 ports downstream toward servers
and 36 ports upstream toward spines.  This means that you need either
36 spines <em>or</em> multiple ports stacked on spines, perhaps on a
chassis-based spine such as an MX240.  The end result is that you are
“wasting” 12x10G ports compared to the 2:1 oversubscription model,
and you likely need more or larger spines.  In reality, 36 server
ports in a 48U rack is probably the most (or close to the most)
you’ll get anyway.  All of this said, though, for the purposes of
this exam, it’s likely best to stick with the number of “downstream”
and “upstream” ports as noted by the difference in port speeds
(i.e., 10G vs. 40G or 40G vs 100G).</p>
</div>
</div>
<div class="section" id="ip-fabric-best-practices">
<span id="best-practices"></span><h2>IP Fabric Best Practices<a class="headerlink" href="#ip-fabric-best-practices" title="Permalink to this headline">¶</a></h2>
<p>There is one critical consideration to make when selecting links between
spines and leafs: bandwdith.  If you go the <a class="reference internal" href="#ibgp"><span class="std std-ref">iBGP</span></a> route (and you
use OSPF or use different metrics for different bandwidths in IS-IS),
your ECMP will be affected if you have mixed uplink bandwidth from your
leafs (such as 10G and 40G).  The result is that you will have some
unutilized links (except in failure scenarios).</p>
<p>However, with eBGP, link bandwidth is not considered for path
calculation.  If your design uses different bandwidth links, this might
initially seem like a good thing because it results in all links being
utilized.  However, they are not intelligently utilized.  You can easily
exceed the utilization of the lower capacity links, resulting in either
service degradation or complete outage conditions (depending on your
SLAs).</p>
<p>For this reason, in either design, it is critical to ensure that all
paths to a given destination from all possible ingress points have the
same total link bandwidth.  This makes managing oversubscription and
scaling much easier.</p>
<p>All swithces at a given stage (spine, leaf, etc.) should be of the same
model.  This isn’t strictly required so long as they can all support the
same features, but if you choose to use different switches, you will be
limited by the smallest number of ports available.  Another
consideration is that some switches may hash traffic differently than
others, leading to unpredictable load sharing characteristics.  In other
words, it’s okay if your spines and leafs are different models, but all
of your spines should be the same model, and all of your leafs should be
the same model.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last"><em>Technically</em> you aren’t limited by the number of ports.  However,
this section is all about best practices.  So, in the spirit of best
practices, don’t try to mix and match models in the same pod.</p>
</div>
<p>If you have a use case for different spine switches in different pods,
then you can use different spine switches in different pods.  An example
of this might be for “bug diversity.”  In other words, you don’t want
all of your global data centers to be hit by the same platform/OS bug at
the same time, so you might deploy different vendors or platforms in
each fabric pod.  However, inside of any given pod, you should still use
the same model switch.</p>
<p>When connecting leaf switches to spine switches, every leaf should be
connected to every spine.  Again, you can get away with not doing this,
but to do so is to invite heartache.  If you’re thinking of doing it for
scaling reasons, consider implementing a 5-stage IP fabric instead.
This brings some different complexity (not covered here), but it also
brings easier and greater scalability without the risks of
unintentionally oversubscribing or modifying the predictability of some
of your fabric switches but not others.</p>
</div>
<div class="section" id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">¶</a></h2>
<dl class="docutils">
<dt>TODO: Add configuration examples for an IGP with iBGP, eBGP with iBGP,</dt>
<dd>and straight eBGP.</dd>
</dl>
<p class="rubric">Footnotes</p>
<table class="docutils footnote" frame="void" id="f1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[1]</a></td><td><a class="reference external" href="https://www.amazon.com/Juniper-QFX5100-Comprehensive-Building-Next-Generation/dp/1491949570/">Juniper QFX5100 Series</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="f2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[2]</a></td><td><a class="reference external" href="https://tools.ietf.org/html/rfc7938#section-5.2">RFC7938: Use of BGP in Large-Scale Data Centers, Section 5.2: EBGP Configuration for Clos Topology</a></td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="f3" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id7">[3]</a></td><td><a class="reference external" href="https://learning.oreilly.com/library/view/bgp-in-the/9781491983416/">BGP in the Data Center, Chapter 2, ASN Numbering Model</a></td></tr>
</tbody>
</table>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">jncip-dc-notes</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="dc-deployment-and-management.html">Data Center Deployment and Management</a></li>
<li class="toctree-l1"><a class="reference internal" href="mc-lag.html">Multi-Chassis LAG (MC-LAG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="layer-2-fabrics.html">Layer 2 Fabrics</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Layer 3 Fabrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#stage-clos-architecture">3-Stage Clos Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ip-fabric-routing">IP Fabric Routing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#ibgp">iBGP</a></li>
<li class="toctree-l3"><a class="reference internal" href="#ebgp">eBGP</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#ip-fabric-scaling">IP Fabric Scaling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ip-fabric-best-practices">IP Fabric Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="#configuration">Configuration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="vxlan.html">VXLAN</a></li>
<li class="toctree-l1"><a class="reference internal" href="vxlan-evpn.html">EVPN VXLAN Signaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="lab-objectives.html">Technology-Oriented Labs</a></li>
<li class="toctree-l1"><a class="reference internal" href="additional-resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributors.html">Contributors</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="layer-2-fabrics.html" title="previous chapter">Layer 2 Fabrics</a></li>
      <li>Next: <a href="vxlan.html" title="next chapter">VXLAN</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Tyler Christiansen.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.8.5</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/layer-3-fabrics.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>